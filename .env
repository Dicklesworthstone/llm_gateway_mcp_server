# LLM Gateway MCP Server
# Environment Variables Configuration Example

# Server Configuration
SERVER_NAME=LLM Gateway
SERVER_PORT=8000
SERVER_HOST=0.0.0.0
SERVER_WORKERS=4
SERVER_DEBUG=false

# Logging Configuration
LOG_LEVEL=INFO                         # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FILE=logs/llm_gateway.log          # Set to empty to disable file logging
USE_RICH_LOGGING=true                  # Enable rich formatted console logging

# Cache Configuration
CACHE_ENABLED=true                     # Enable response caching
CACHE_TTL=86400                        # Default TTL in seconds (24 hours)
CACHE_DIR=.cache                       # Cache directory
CACHE_MAX_ENTRIES=10000                # Maximum in-memory cache entries
CACHE_FUZZY_MATCH=true                 # Enable fuzzy matching for cache lookups

# Provider API Keys
OPENAI_API_KEY=sk-...                  # OpenAI API key
ANTHROPIC_API_KEY=sk-ant-...           # Anthropic API key
DEEPSEEK_API_KEY=sk-...                # DeepSeek API key
GEMINI_API_KEY=...                     # Google Gemini API key

# Provider Default Models
OPENAI_DEFAULT_MODEL=gpt-4o-mini       # Default model for OpenAI
ANTHROPIC_DEFAULT_MODEL=claude-3-5-haiku-latest  # Default model for Anthropic
DEEPSEEK_DEFAULT_MODEL=deepseek-chat   # Default model for DeepSeek
GEMINI_DEFAULT_MODEL=gemini-2.0-flash-lite  # Default model for Gemini

# Provider Token Limits
OPENAI_MAX_TOKENS=8192                 # Max tokens for OpenAI completions
ANTHROPIC_MAX_TOKENS=200000            # Max tokens for Anthropic completions
DEEPSEEK_MAX_TOKENS=8192               # Max tokens for DeepSeek completions
GEMINI_MAX_TOKENS=8192                 # Max tokens for Gemini completions

# Vector Embedding Service
EMBEDDING_CACHE_DIR=.embeddings        # Embedding cache directory
EMBEDDING_DEFAULT_MODEL=text-embedding-3-small  # Default embedding model

# Advanced Configuration
REQUEST_TIMEOUT=60                     # Default request timeout in seconds
RATE_LIMIT_ENABLED=false               # Enable rate limiting
MAX_CONCURRENT_REQUESTS=20             # Maximum concurrent requests